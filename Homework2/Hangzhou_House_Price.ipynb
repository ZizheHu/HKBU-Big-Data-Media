{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zizhehu/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/zizhehu/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "r=requests.get(\"https://hz.fang.anjuke.com/loupan/all/?district=1\")\n",
    "r.text\n",
    "mypage=BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取所有链接信息\n",
    "urls = []\n",
    "houseprice = []\n",
    "housename = []\n",
    "location_1 = []\n",
    "location_2 = []\n",
    "location_3 = []\n",
    "huxing_final = []\n",
    "mianji_final = []\n",
    "\n",
    "for i in range(0,14):\n",
    "    url = 'https://hz.fang.anjuke.com/loupan/all/p'+str(i+1)+'/s?district=1'\n",
    "    urls.append(url)  \n",
    "\n",
    "for url in urls:\n",
    "    page_name = requests.get(url).text\n",
    "    mypage = BeautifulSoup(page_name,'html.parser')\n",
    "\n",
    "#1.抓取住宅名称\n",
    "    name2s=mypage.find_all('span',attrs={'class':'items-name'})\n",
    "    name2=name2s[0]\n",
    "\n",
    "    \n",
    "    for name2 in name2s:\n",
    "        housename.append(name2.text)\n",
    "        \n",
    "#2.3.4抓取地区信息\n",
    "    addresses=mypage.find_all('span',attrs={'class':'list-map'})\n",
    "    address=addresses[0]\n",
    "\n",
    "    \n",
    "    for address in addresses:\n",
    "        address_=address.text\n",
    "\n",
    "        address_1=address_.split()[1]\n",
    "        address_2=address_.split()[2]\n",
    "        address_3=address_.split()[4]\n",
    "\n",
    "        location_1.append(address_1)\n",
    "        location_2.append(address_2)\n",
    "        location_3.append(address_3)\n",
    "\n",
    "#开始抓取户型和面积\n",
    "    huxings=mypage.find_all('a',attrs={'class':'huxing'})\n",
    "    huxing_0=huxings[0]\n",
    "    huxing_1=huxing_0.find_all('span')\n",
    "\n",
    "\n",
    "    for huxing_0 in huxings:\n",
    "        huxing_1=huxing_0.find_all('span')\n",
    "        mymianji1=huxing_1[-1].text\n",
    "        mymianji2=mymianji1[5:]\n",
    "        huxing_final.append(str_huxing)\n",
    "        mianji_final.append(mymianji2)\n",
    "\n",
    "#5.抓取户型信息\n",
    "        huxing_2=huxing_1[0:-1]\n",
    "        myhuxing1 = []\n",
    "        for span in huxing_2:\n",
    "            myhuxing1.append(span.text)\n",
    "            str_huxing=''.join(myhuxing1)\n",
    "\n",
    "\n",
    "#6.抓取面积信息\n",
    "\n",
    "\n",
    "#7.抓取房价\n",
    "    myprices=mypage.find_all('p',attrs={'class':'price'})\n",
    "    myprice=myprices[0]\n",
    "\n",
    "    for myprice in myprices:\n",
    "        houseprice.append(myprice.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#写入csv\n",
    "with open('hangzhou.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = ['Housename','District','Area','Street','House Stype','Acreage','Houseprice']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    writer.writerows(zip(housename,location_1,location_2,location_3,huxing_final,mianji_final,houseprice))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
